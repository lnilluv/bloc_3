{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================== CATBOOST ===================================\n",
      "Loading dataset...\n",
      "0:\tlearn: 0.7120397\ttest: 0.7005838\tbest: 0.7005838 (0)\ttotal: 193ms\tremaining: 1m 42s\n",
      "100:\tlearn: 0.7710880\ttest: 0.7484220\tbest: 0.7493947 (22)\ttotal: 5.27s\tremaining: 22.4s\n",
      "200:\tlearn: 0.7741548\ttest: 0.7500000\tbest: 0.7506767 (194)\ttotal: 10.3s\tremaining: 16.8s\n",
      "300:\tlearn: 0.7780032\ttest: 0.7489489\tbest: 0.7512019 (212)\ttotal: 15.6s\tremaining: 11.9s\n",
      "400:\tlearn: 0.7807004\ttest: 0.7489464\tbest: 0.7512019 (212)\ttotal: 21.4s\tremaining: 6.88s\n",
      "500:\tlearn: 0.7831062\ttest: 0.7512019\tbest: 0.7519520 (498)\ttotal: 27.4s\tremaining: 1.59s\n",
      "529:\tlearn: 0.7844996\ttest: 0.7517221\tbest: 0.7519520 (498)\ttotal: 29.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.751951952\n",
      "bestIteration = 498\n",
      "\n",
      "Shrink model to first 499 iterations.\n",
      "{'border_count': 183, 'depth': 9, 'iterations': 530, 'l2_leaf_reg': 6, 'learning_rate': 0.10423350877784786, 'loss_function': 'Logloss', 'rsm': 0.7551020408163265}\n",
      "0.9863790568828726\n",
      "f1-score on train set :  0.7772846934937946\n",
      "f1-score on test set :  0.751951951951952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "f1 = make_scorer(f1_score , average='micro')\n",
    "\n",
    "#  {'depth': 5, 'iterations': 500, 'learning_rate': 0.01}\n",
    "print(\" CATBOOST \".center(80, \"=\"))\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "df = pd.read_csv(\"/Users/pryda/Documents/Projets_Jedha/2_ConversioNRate/conversion_data_train.csv\")\n",
    "\n",
    "X = df.drop([\"converted\"], axis=1)\n",
    "y = df[\"converted\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "categoricals = [\"country\", \"new_user\", \"source\"]\n",
    "\n",
    "# model = CatBoostClassifier(iterations=500, learning_rate=0.01, depth=5, loss_function=\"Logloss\", eval_metric=\"F1\", cat_features=categoricals, verbose=100) # poop\n",
    "\n",
    "# model = CatBoostClassifier(loss_function=\"Logloss\", eval_metric=\"F1\", cat_features=categoricals, verbose=100) # 0.777 train, 0.7517 test\n",
    "\n",
    "# model = CatBoostClassifier(loss_function=\"Logloss\", eval_metric=\"F1\", cat_features=categoricals, verbose=100, depth=9, learning_rate=0.2, rsm=1) # f1-score on train set :  0.7910958904109588\n",
    "# f1-score on test set :  0.7397585592717197\n",
    "\n",
    "cbc = CatBoostClassifier(cat_features=categoricals, eval_metric=\"F1\", verbose=100)\n",
    "param_dist = {\n",
    "    # \"learning_rate\": np.linspace(0,0.2,5),\n",
    "    # \"depth\": randint(3, 10),\n",
    "    # \"iterations\": randint(100, 500),\n",
    "    \"rsm\": np.linspace(0,1),\n",
    "    \"learning_rate\": sp_randFloat(0.01, 0.8),\n",
    "    \"depth\": sp_randInt(6, 10),\n",
    "    \"iterations\": sp_randInt(10, 1000),\n",
    "    \"border_count\": sp_randInt(1, 255),\n",
    "    'l2_leaf_reg': sp_randInt(1, 10),\n",
    "    'loss_function': ['Logloss', 'CrossEntropy'],\n",
    "}\n",
    "\n",
    "model = RandomizedSearchCV(cbc, param_distributions=param_dist, n_iter=10, cv=10, scoring=f1, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, Y_train, eval_set=(X_test, Y_test))\n",
    "\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(model.best_params_)\n",
    "print(model.best_score_)\n",
    "\n",
    "print(\"f1-score on train set : \", f1_score(Y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "\n",
    "# model.save_model(\"catboost_v1_randomsearch\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Concatenate our train and test set to train your best classifier on all data with labels\n",
    "X = np.append(X_train,X_test,axis=0)\n",
    "Y = np.append(Y_train,Y_test)\n",
    "\n",
    "model.fit(X,Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/Users/pryda/Documents/Projets_Jedha/2_ConversioNRate/conversion_data_test.csv\")\n",
    "\n",
    "predictions = model.predict(df_test)\n",
    "print(predictions)\n",
    "\n",
    "pred_df = pd.DataFrame(columns=['converted'], data=predictions)\n",
    "# pred_df = pd.DataFrame({ \"converted\": np.array(predictions)[:, -1] })\n",
    "pred_df.to_csv(f\"conversion_data_test_predictions_LV_catboost_split{datetime.datetime.now().timestamp()}.csv\",\n",
    "               index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}